{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import the libraries, create an AzureML lazy client"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "import pandas as pd\r\n",
        "from azure.identity import ClientSecretCredential\r\n",
        "from azure.ai.ml import MLClient\r\n",
        "from azure.ai.ml import command\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml import Input\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "credential = ClientSecretCredential('9a43d1e2-267b-4087-9e6a-1e8d0585ef1e', '25a6e569-51d3-4d78-ac63-1cfd8ee940c9', 'VHk8Q~gNBMuIgyGv~8mwPfbGQ2LX-WuOXcJUrcHs')\r\n",
        "# Get a handle to the workspace\r\n",
        "ml_client = MLClient(\r\n",
        "    credential=credential,\r\n",
        "    subscription_id=\"ed30c0d8-b03a-454d-96a8-6fe54400a879\",\r\n",
        "    resource_group_name=\"dev-iot-group\",\r\n",
        "    workspace_name=\"roymlws\",\r\n",
        ")\r\n",
        "print(ml_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.client_secret.ClientSecretCredential object at 0x7fcf2e642bc0>,\n         subscription_id=ed30c0d8-b03a-454d-96a8-6fe54400a879,\n         resource_group_name=dev-iot-group,\n         workspace_name=roymlws)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1683003112388
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "train_src_dir = \"./src\"\r\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003112703
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provide the scalable compute cluster"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\r\n",
        "\r\n",
        "# Name assigned to the compute cluster\r\n",
        "cpu_compute_target = \"roycpucluster\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # let's see if the compute target already exists\r\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\r\n",
        "    print(\r\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\r\n",
        "    )\r\n",
        "\r\n",
        "except Exception as e:\r\n",
        "    print(\"Creating a new cpu compute target...\")\r\n",
        "    print(e)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You already have a cluster named roycpucluster, we'll reuse it as is.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003113270
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a training script python file. This will be uploaded to compute for execution."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/main.py\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\r\n",
        "\r\n",
        "def main():\r\n",
        "    \"\"\"Main function of the script.\"\"\"\r\n",
        "\r\n",
        "    # input and output arguments\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\r\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\r\n",
        "    # parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\r\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\r\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\r\n",
        "    args = parser.parse_args()\r\n",
        "   \r\n",
        "    # Start Logging\r\n",
        "    mlflow.start_run()\r\n",
        "\r\n",
        "    # enable autologging\r\n",
        "    mlflow.sklearn.autolog()\r\n",
        "\r\n",
        "    ###################\r\n",
        "    #<prepare the data>\r\n",
        "    ###################\r\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\r\n",
        "\r\n",
        "    print(\"input data:\", args.data)\r\n",
        "    \r\n",
        "    # credit_df = pd.read_csv(args.data, header=1, index_col=0)\r\n",
        "    stocks_df = pd.read_parquet(args.data)\r\n",
        "\r\n",
        "    # Select features and target\r\n",
        "    features = ['rolling_average', 'rolling_median']\r\n",
        "    target = 'Volume'\r\n",
        "\r\n",
        "    stocks_df = stocks_df[features+[target]]\r\n",
        "\r\n",
        "    mlflow.log_metric(\"num_samples\", stocks_df.shape[0])\r\n",
        "    mlflow.log_metric(\"num_features\", stocks_df.shape[1] - 1)\r\n",
        "\r\n",
        "    train_df, test_df = train_test_split(\r\n",
        "        stocks_df,\r\n",
        "        test_size=args.test_train_ratio,\r\n",
        "    )\r\n",
        "    ####################\r\n",
        "    #</prepare the data>\r\n",
        "    ####################\r\n",
        "\r\n",
        "    ##################\r\n",
        "    #<train the model>\r\n",
        "    ##################\r\n",
        "\r\n",
        "    # Extracting the label column\r\n",
        "    y_train = train_df.pop(target)\r\n",
        "\r\n",
        "    # convert the dataframe values to array\r\n",
        "    X_train = train_df.values\r\n",
        "\r\n",
        "    # Extracting the label column\r\n",
        "    y_test = test_df.pop(target)\r\n",
        "\r\n",
        "    # convert the dataframe values to array\r\n",
        "    X_test = test_df.values\r\n",
        "\r\n",
        "    print(f\"Training with data of shape {X_train.shape}\")\r\n",
        "\r\n",
        "    model = HistGradientBoostingRegressor( learning_rate=args.learning_rate,\r\n",
        "        verbose=1, random_state=None\r\n",
        "    )\r\n",
        "    model.fit(X_train, y_train)\r\n",
        "\r\n",
        "    y_pred = model.predict(X_test)\r\n",
        "\r\n",
        "    # Calculate the Mean Absolute Error and Mean Squared Error\r\n",
        "    mae = mean_absolute_error(y_test, y_pred)\r\n",
        "    mse = mean_squared_error(y_test, y_pred)\r\n",
        "    print(\"mae=\",mae,\"mse=\",mse)\r\n",
        "    ###################\r\n",
        "    #</train the model>\r\n",
        "    ###################\r\n",
        "\r\n",
        "    ##########################\r\n",
        "    #<save and register model>\r\n",
        "    ##########################\r\n",
        "    # Registering the model to the workspace\r\n",
        "    print(\"Registering the model via MLFlow\")\r\n",
        "    mlflow.sklearn.log_model(\r\n",
        "        sk_model=model,\r\n",
        "        registered_model_name=args.registered_model_name,\r\n",
        "        artifact_path=args.registered_model_name,\r\n",
        "    )\r\n",
        "\r\n",
        "    # Saving the model to a file\r\n",
        "    mlflow.sklearn.save_model(\r\n",
        "        sk_model=model,\r\n",
        "        path=os.path.join(args.registered_model_name, \"trained_model\"),\r\n",
        "    )\r\n",
        "    ###########################\r\n",
        "    #</save and register model>\r\n",
        "    ###########################\r\n",
        "    \r\n",
        "    # Stop Logging\r\n",
        "    mlflow.end_run()\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/main.py\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install -U azureml-fsspec"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from azure.ai.ml import command\r\n",
        "# from azure.ai.ml.entities import Data\r\n",
        "# from azure.ai.ml import Input\r\n",
        "# from azure.ai.ml.constants import AssetTypes, InputOutputModes\r\n",
        "\r\n",
        "# registered_model_name = \"stock_prices_model\"\r\n",
        "# https://royadlsgen2.dfs.core.windows.net/royadlsfs/staging/prepared_stock_data.parquet\r\n",
        "# abfss://royadlsfs@royadlsgen2.dfs.core.windows.net/staging/prepared_stock_data.parque\r\n",
        "# azureml://subscriptions/ed30c0d8-b03a-454d-96a8-6fe54400a879/resourcegroups/dev-iot-group/workspaces/roymlws/datastores/workspaceworkingdirectory/paths/Users/kaushik.roy1984/stocksml/prepared_stock_data.parquet/\r\n",
        "# filedataset_asset = ml_client.data.get(name=\"storcksdata1\", version=\"3\")\r\n",
        "# print(f\"Data asset URI: {filedataset_asset.path}\")\r\n",
        "# job = command(\r\n",
        "#     inputs=dict(\r\n",
        "#         data=Input(\r\n",
        "#             type=AssetTypes.MLTABLE,\r\n",
        "#             path=filedataset_asset,\r\n",
        "#             mode=InputOutputModes.DIRECT\r\n",
        "#         ),\r\n",
        "#         test_train_ratio=0.2,\r\n",
        "#         learning_rate=0.25,\r\n",
        "#         registered_model_name=registered_model_name,\r\n",
        "#     ),\r\n",
        "#     code=\"./src/\",  # location of source code\r\n",
        "#     command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\r\n",
        "#     environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\r\n",
        "#     compute=\"roycpucluster\",\r\n",
        "#     display_name=\"stock_prices_prediction\",\r\n",
        "# )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data asset URI: azureml://subscriptions/ed30c0d8-b03a-454d-96a8-6fe54400a879/resourcegroups/dev-iot-group/workspaces/roymlws/datastores/workspaceworkingdirectory/paths/Users/kaushik.roy1984/stocksml/prepared_stock_data.parquet/\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682992925810
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a job profile to submit, and mention all the parameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\r\n",
        "from azure.ai.ml import Input\r\n",
        "\r\n",
        "registered_model_name = \"stock_prices_model\"\r\n",
        "filedataset_asset = ml_client.data.get(name=\"storcksdata1\", version=\"3\")\r\n",
        "print(f\"Data asset URI: {filedataset_asset.path}\")\r\n",
        "job = command(\r\n",
        "    inputs=dict(\r\n",
        "        data=Input(\r\n",
        "            type=\"uri_file\",\r\n",
        "            path=filedataset_asset.path,\r\n",
        "        ),\r\n",
        "        test_train_ratio=0.2,\r\n",
        "        learning_rate=0.25,\r\n",
        "        registered_model_name=registered_model_name,\r\n",
        "    ),\r\n",
        "    code=\"./src/\",  # location of source code\r\n",
        "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\r\n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\r\n",
        "    compute=\"roycpucluster\",\r\n",
        "    display_name=\"stock_prices_prediction\",\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data asset URI: azureml://subscriptions/ed30c0d8-b03a-454d-96a8-6fe54400a879/resourcegroups/dev-iot-group/workspaces/roymlws/datastores/workspaceworkingdirectory/paths/Users/kaushik.roy1984/stocksml/prepared_stock_data.parquet/\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003162523
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the job. Every run produces a new job. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_client.create_or_update(job)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003181262
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get ready to deploy"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "\r\n",
        "# Creating a unique name for the endpoint\r\n",
        "online_endpoint_name = \"stocks-endpoint-\" + str(uuid.uuid4())[:8]\r\n",
        "online_endpoint_name"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "'stocks-endpoint-0422eadb'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003187758
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start a managed endpoint. Takes a few minutes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expect the endpoint creation to take a few minutes\r\n",
        "from azure.ai.ml.entities import (\r\n",
        "    ManagedOnlineEndpoint,\r\n",
        "    ManagedOnlineDeployment,\r\n",
        "    Model,\r\n",
        "    Environment,\r\n",
        ")\r\n",
        "\r\n",
        "# create an online endpoint\r\n",
        "endpoint = ManagedOnlineEndpoint(\r\n",
        "    name=online_endpoint_name,\r\n",
        "    description=\"this is an online endpoint\",\r\n",
        "    auth_mode=\"key\",\r\n",
        "    tags={\r\n",
        "        \"training_dataset\": \"stocks_prices\",\r\n",
        "        \"model_type\": \"sklearn.ensemble.HistGradientBoostingRegressor\",\r\n",
        "    },\r\n",
        ")\r\n",
        "\r\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\r\n",
        "\r\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint stocks-endpoint-0422eadb provisioning state: Succeeded\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003286712
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check if endpoint is working"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\r\n",
        "\r\n",
        "print(\r\n",
        "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint \"stocks-endpoint-0422eadb\" with provisioning state \"Succeeded\" is retrieved\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003405955
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the registered model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick the latest version of the model\r\n",
        "latest_model_version = max(\r\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\r\n",
        ")\r\n",
        "print(f'Latest model is version \"{latest_model_version}\" ')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest model is version \"1\" \n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003412310
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit deployment. Takes a few minutes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\r\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\r\n",
        "\r\n",
        "# Expect this deployment to take approximately 6 to 8 minutes.\r\n",
        "# create an online deployment.\r\n",
        "blue_deployment = ManagedOnlineDeployment(\r\n",
        "    name=\"blue\",\r\n",
        "    endpoint_name=online_endpoint_name,\r\n",
        "    model=model,\r\n",
        "    instance_type=\"Standard_DS2_v2\",\r\n",
        "    instance_count=1,\r\n",
        ")\r\n",
        "\r\n",
        "blue_deployment = ml_client.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683004756666
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deploy_dir = \"./deploy\"\r\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003971333
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a sample request json"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {deploy_dir}/sample-request.json\r\n",
        "{\r\n",
        "  \"input_data\": {\r\n",
        "    \"columns\": [0,1],\r\n",
        "    \"index\": [0],\r\n",
        "    \"data\": [\r\n",
        "            [124800,124880]\r\n",
        "        ]\r\n",
        "  }\r\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./deploy/sample-request.json\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the deployed service"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the blue deployment with some sample data\r\n",
        "ml_client.online_endpoints.invoke(\r\n",
        "    endpoint_name=online_endpoint_name,\r\n",
        "    request_file=\"./deploy/sample-request.json\",\r\n",
        "    deployment_name=\"blue\",\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "'[125667.50795053323]'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683003980394
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optionally delete endpoint ot save costs"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7fa0014d0fd0>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".............................................................................................."
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683001232208
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use this code in a score.py to get real time predictions. Use your own key"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "# The example below assumes JSON formatting which may be updated\r\n",
        "# depending on the format your endpoint expects.\r\n",
        "# More information can be found here:\r\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\r\n",
        "data =  {\r\n",
        "  \"input_data\": {\r\n",
        "    \"columns\": [0,1],\r\n",
        "    \"index\": [0],\r\n",
        "    \"data\": [\r\n",
        "            [124800,124880]\r\n",
        "        ]\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'https://stocks-endpoint-0422eadb.canadacentral.inference.ml.azure.com/score'\r\n",
        "# Replace this with the primary/secondary key or AMLToken for the endpoint\r\n",
        "api_key = 'V9Hz8RMuuiU7TS5rbeNdFnvmyUYnNCb6'\r\n",
        "if not api_key:\r\n",
        "    raise Exception(\"A key should be provided to invoke the endpoint\")\r\n",
        "\r\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\r\n",
        "# Remove this header to have the request observe the endpoint traffic rules\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'blue' }\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "b'[125667.50795053323]'\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683004653019
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}